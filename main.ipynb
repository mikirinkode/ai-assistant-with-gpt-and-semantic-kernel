{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.3.8)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (0.23.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore<0.16.0,>=0.15.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (0.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpcore<0.16.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n",
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.This is a test.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "openai_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# promt -> input user\n",
    "# system_content -> role the ai that we want\n",
    "# model -> used gpt model\n",
    "# stream -> to display the result in real time (like typing)\n",
    "def chat(prompt, system_content = None, model = \"gpt-4\", stream = False):\n",
    "  system_content = system_content if system_content != None else \"You are a personal AI Assistant that helps user with their daily tasks.\"\n",
    "  \n",
    "  messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    "  \n",
    "  print(messages)\n",
    "  \n",
    "  if stream:\n",
    "    completion = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    )\n",
    "    for chunk in completion:\n",
    "      if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "  else: \n",
    "    completion = client.chat.completions.create(\n",
    "      model = model,\n",
    "      messages = messages\n",
    "    )\n",
    "    print(completion)\n",
    "    # print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer(content):\n",
    "    return chat(content, system_content=\"\"\"\n",
    "                    You are a summarizer AI that summarizes the given content in two sentences.\n",
    "                    The output format should be in a list\n",
    "                \"\"\")\n",
    "\n",
    "def translator(content):\n",
    "    return chat(content, system_content=\"\"\"\n",
    "                    You are a translator AI that translates the given content to user's requested language.\n",
    "                    Don't make assumptions about what language the user wants to translate to.\n",
    "                    Ask for clarification if a user doesn't specify a language.\n",
    "                \"\"\".strip())\n",
    "    \n",
    "def english_grammar_master(content):\n",
    "    return chat(content, system_content=\"\"\"\n",
    "                    You are an English grammar master that corrects the given content.\n",
    "                \"\"\".strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"You are a translator AI that translates the given content to user's requested language.\\n                    Don't make assumptions about what language the user wants to translate to.\\n                    Ask for clarification if a user doesn't specify a language.\"}, {'role': 'user', 'content': 'say hello in japanese'}]\n",
      "ChatCompletion(id='chatcmpl-8bLiXkaYjcwRWFwedzjCu4lxuH2KW', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='In Japanese, \"Hello\" is \"こんにちは\" (Konnichiwa).', role='assistant', function_call=None, tool_calls=None), logprobs=None)], created=1703912309, model='gpt-4-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=59, total_tokens=75))\n"
     ]
    }
   ],
   "source": [
    "translator(\"say hello in japanese\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
